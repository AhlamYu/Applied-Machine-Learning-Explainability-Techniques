{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring  ALIBI (Algorithms for explaining machine learning models)\n",
    "## CHAPTER 09 - *Other popular XAI frameworks*\n",
    "\n",
    "From **Applied Machine Learning Explainability Techniques** by [**Aditya Bhattacharya**](https://www.linkedin.com/in/aditya-bhattacharya-b59155b6/), published by **Packt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Previously, in [chapter 2](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter02), we have covered the [Counterfactual Explanation Tutorial](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter02/Counterfactual_structured_data.ipynb), where you have received some exposure on the [ALIBI framework](https://github.com/SeldonIO/alibiE). In this tutorial, you will get a deeper exposure to the ALIBI framework on a different problem. We will use the same Occupancy Detection Dataset used in the [DiCE tutorial](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter09/DiCE_example.ipynb). So, the initial part of the tutorial might look same, but the model explainabilty part will be different as we will be using various components from the ALIBI framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following libraries in Google Colab or your local environment, if not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas numpy matplotlib seaborn scikit-learn tensorflow alibi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import alibi\n",
    "from alibi.explainers import AnchorTabular, CEM, CounterfactualProto\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Occupancy Detection dataset | [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+#)**\n",
    "\n",
    "Original Source: https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+#\n",
    "\n",
    "Discovered from : https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Occupancy%20Detection\n",
    "\n",
    "- This data set has 20560 rows and 7 attributes which are divided into 3 data sets for training, validation  and testing.\n",
    "\n",
    "- The data set provides experimental data used for binary classification (room occupancy of an office room) from Temperature, Humidity, Light and CO2. \n",
    "\n",
    "- Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.This dataset is recommended for classification based problems.\n",
    "\n",
    "This data set has been sourced from the Machine Learning Repository of University of California, Irvine [Occupancy Detection Data Set (UC Irvine)](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+#). The UCI page mentions the following publication [Accurate occupancy detection of an office room from light, temperature, humidity and CO2 measurements using statistical learning models. Luis M. Candanedo, VÃ©ronique Feldheim. Energy and Buildings. Volume 112, 15 January 2016, Pages 28-39](https://www.researchgate.net/profile/Luis_Candanedo_Ibarra/publication/285627413_Accurate_occupancy_detection_of_an_office_room_from_light_temperature_humidity_and_CO2_measurements_using_statistical_learning_models/links/5b1d843ea6fdcca67b690c28/Accurate-occupancy-detection-of-an-office-room-from-light-temperature-humidity-and-CO2-measurements-using-statistical-learning-models.pdf?origin=publication_detail) as the original source of the data set.\n",
    "\n",
    "And thanks to Data Science Dojo - https://code.datasciencedojo.com/ - for curating this dataset, thus making it more discoverable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will read the training data, validation and test data\n",
    "df_train = pd.read_csv('datasets/Occupancy_Detection_Data/train.csv')\n",
    "df_valid = pd.read_csv('datasets/Occupancy_Detection_Data/valid.csv')\n",
    "df_test = pd.read_csv('datasets/Occupancy_Detection_Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/4/2015 17:51</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/4/2015 17:51</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/4/2015 17:53</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/4/2015 17:54</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/4/2015 17:55</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "0  2/4/2015 17:51        23.18   27.2720  426.0  721.25       0.004793   \n",
       "1  2/4/2015 17:51        23.15   27.2675  429.5  714.00       0.004783   \n",
       "2  2/4/2015 17:53        23.15   27.2450  426.0  713.50       0.004779   \n",
       "3  2/4/2015 17:54        23.15   27.2000  426.0  708.25       0.004772   \n",
       "4  2/4/2015 17:55        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "   Occupancy  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Occupancy Detection Dataset\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Original Source: https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+#\n",
      "Discovered from : https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Occupancy%20Detection\n",
      "\n",
      "---\n",
      "\n",
      "- This data set has 20560 rows and 7 attributes which are divided into 3 data sets for training, validation  and testing.\n",
      "\n",
      "- The data set provides experimental data used for binary classification (room occupancy of an office room) from Temperature, Humidity, Light and CO2. \n",
      "\n",
      "- Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.This dataset is recommended for classification based problems.\n",
      "\n",
      "---\n",
      "\n",
      "### Data Dictionary \n",
      "As mentioned in : https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Occupancy%20Detection\n",
      "\n",
      "| Column   Position \t| Atrribute Name \t| Definition                                                                                           \t| Data Type    \t| Example                                        \t| % Null Ratios \t|\n",
      "|-------------------\t|----------------\t|------------------------------------------------------------------------------------------------------\t|--------------\t|------------------------------------------------\t|---------------\t|\n",
      "| 1                 \t| Date           \t| Date & time in year-month-day hour:minute:second format                                              \t| Qualitative  \t| 2/4/2015 17:57, 2/4/2015 17:55, 2/4/2015 18:06\t\t \t| 0             \t|\n",
      "| 2                 \t| Temperature    \t| Temperature in degree Celcius                                                                        \t| Quantitative \t| 23.150, 23.075, 22.890                         \t| 0             \t|\n",
      "| 3                 \t| Humidity       \t| Relative humidity in percentage                                                                      \t| Quantitative \t| 27.272000, 27.200000, 27.390000                \t| 0             \t|\n",
      "| 4                 \t| Light          \t| Illuminance measurement in unit Lux                                                                  \t| Quantitative \t| 426.0, 419.0, 0.0\t                              \t| 0             \t|\n",
      "| 5                 \t| CO2            \t| CO2 in parts per million (ppm)                                                                       \t| Quantitative \t| 489.666667,   495.500000, 534.500000           \t| 0             \t|\n",
      "| 6                 \t| HumidityRatio  \t| Humadity ratio:  Derived quantity from temperature and   relative humidity, in kgwater-vapor/kg-air  \t| Quantitative \t| 0.004986, 0.005088, 0.005203                   \t| 0             \t|\n",
      "| 7                 \t| Occupancy      \t| Occupied or not: 1 for occupied and 0 for not occupied                                               \t| Quantitative \t| 1, 0                                           \t| 0             \t|\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "### Acknowledgement\n",
      "\n",
      "\n",
      "This data set has been sourced from the Machine Learning Repository of University of California, Irvine [Occupancy Detection Data Set (UC Irvine)](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+#). The UCI page mentions the following publication [Accurate occupancy detection of an office room from light, temperature, humidity and CO2 measurements using statistical learning models. Luis M. Candanedo, VÃƒÂ©ronique Feldheim. Energy and Buildings. Volume 112, 15 January 2016, Pages 28-39](https://www.researchgate.net/profile/Luis_Candanedo_Ibarra/publication/285627413_Accurate_occupancy_detection_of_an_office_room_from_light_temperature_humidity_and_CO2_measurements_using_statistical_learning_models/links/5b1d843ea6fdcca67b690c28/Accurate-occupancy-detection-of-an-office-room-from-light-temperature-humidity-and-CO2-measurements-using-statistical-learning-models.pdf?origin=publication_detail) as the original source of the data set.\n",
      "\n",
      "All thanks to Data Science Dojo - https://code.datasciencedojo.com/ - for curating this dataset, thus making it more discoverable! \n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset description\n",
    "with open('datasets/Occupancy_Detection_Data/description.txt') as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8143, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check dataset dimensions\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio',\n",
       "       'Occupancy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6414\n",
       "1    1729\n",
       "Name: Occupancy, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Occupancy'].value_counts().plot(kind='pie')\n",
    "df_train['Occupancy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8143 entries, 0 to 8142\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           8143 non-null   object \n",
      " 1   Temperature    8143 non-null   float64\n",
      " 2   Humidity       8143 non-null   float64\n",
      " 3   Light          8143 non-null   float64\n",
      " 4   CO2            8143 non-null   float64\n",
      " 5   HumidityRatio  8143 non-null   float64\n",
      " 6   Occupancy      8143 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 445.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset contains close to 8143 records and 6 features. The `date` feature doesn't seem to be relevant to detect room occupancy and we want to perform this detection solely based on the sensor values. So, we will drop this feature. We may need to perform further data normalization or transformation, but luckily there is no missing values, and thus no need for data imputation or additional steps to handle missing value. In the next step, we will perform some preliminary data processing and exploration, required for building the model. But I do recommend all of you to perform a detailed EDA, data processing, feature engineering in order to get a well trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a generic scikit-learn pipeline for training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop un-necessary features\n",
    "features_to_drop = ['date']\n",
    "target_variable = 'Occupancy'\n",
    "y_train = df_train[target_variable]\n",
    "y_valid = df_valid[target_variable]\n",
    "y_test = df_test[target_variable]\n",
    "\n",
    "numeric = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio'] # All features in this dataset is numerical\n",
    "categorical = [] # No categorical feature in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_not_wanted_features(df):\n",
    "    '''\n",
    "    Function to drop unwanted features\n",
    "    '''    \n",
    "    df.drop(columns='date', inplace=True)\n",
    "    df.drop(columns='Occupancy', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = drop_not_wanted_features(df_train)\n",
    "df_valid = drop_not_wanted_features(df_valid)\n",
    "df_test = drop_not_wanted_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create preprocessing pipelines for both numeric and categorical data.\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numeric_transformer, numeric),\n",
    "        ('categorical', categorical_transformer, categorical)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "# You can further add other custom pipelines\n",
    "clf = Pipeline(steps=[('preprocessor', column_transformer),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators=300,\n",
    "                                                            random_state=123))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770303527481542"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score on validation dataset\n",
    "model.score(df_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951594746716698"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score on test dataset\n",
    "accuracy_score(model.predict(df_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9501350997513132"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC_AUC score on test dataset\n",
    "roc_auc_score(model.predict(df_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explainability using ALIBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ALIBI](https://github.com/SeldonIO/alibi/tree/master/doc/source/examples) supports a wide range of operation with various types of dataset (tabular, images, text etc.). Previously in [Chapter 2](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter02/Counterfactual_structured_data.ipynb), we have explored only the counterfactual explanations, now we will explore the other explainability methods available in ALIBI as well. Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor Explainations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO-DO - Define what is anchor explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_transform(numpy_array, all_features):\n",
    "    return pd.DataFrame(numpy_array, columns = all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: model.predict_proba(reverse_transform(x, list(df_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = AnchorTabular(predict_fn, \n",
    "                          feature_names=list(df_train.columns), \n",
    "                          seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "  'name': 'AnchorTabular',\n",
       "  'type': ['blackbox'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {'disc_perc': [25, 50, 75], 'seed': 123},\n",
       "  'version': '0.6.2'}\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.fit(df_train.values, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting an anchor\n",
    "\n",
    "For model explainability using anchors, first we need an anchor for the prediction of the first observation in the test set. An anchor is a sufficient condition - that is, when the anchor holds, the prediction should be the same as the prediction for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  not_occupied\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "class_names = ['not_occupied', 'occupied']\n",
    "print('Prediction: ', class_names[explainer.predictor(df_test.values[idx].reshape(1, -1))[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to set a precision threshold, which will be like the confidence interval from the anchor. We will set the precision threshold to 0.8. This means that predictions on observations where the anchor holds will be the same as the prediction on the explained instance at least 80% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: CO2 > 439.00\n",
      "Precision: 0.83\n",
      "Coverage: 0.75\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(df_test.values[idx], threshold=0.8)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, we can increase or decrease the precision to best suit our needs.\n",
    "\n",
    "Next, let us get try to get an anchor for a prediction for the `occupied` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  occupied\n",
      "Anchor: Light > 256.38 AND CO2 > 638.83\n",
      "Precision: 0.98\n",
      "Coverage: 0.20\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "class_names = ['not_occupied', 'occupied']\n",
    "print('Prediction: ', class_names[explainer.predictor(df_test.values[idx].reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(df_test.values[idx], threshold=0.8)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result, the anchor from the occupied class makes more sense, as it suggests that when the light is on with a certain intensity and when the CO2 level is high, this indicate that the room is occupied.\n",
    "\n",
    "Next let us cover another different method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Explanations Method (CEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Contrastive Explanation Method (CEM) can produce explanations for black-box models with respect to pertinent positives (PP) and pertinent negatives (PN). For PP, it finds what should be minimally and sufficiently present (e.g. important pixels in an image) to justify its classification. PN on the other hand identify what should be minimally and necessarily absent from the explained instance in order to maintain the original prediction. Check out the [original research lierature](https://arxiv.org/pdf/1802.07623.pdf) to get a better understanding of the theoretical concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CEM with pertinent negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the data instance selected : not_occupied\n",
      "Prediction probabilities : [0.52333333 0.47666667]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "X = df_test[idx:idx+1]\n",
    "\n",
    "print(f'Prediction for the data instance selected : {class_names[model.predict(X)[0]]}')\n",
    "print(f'Prediction probabilities : {model.predict_proba(X)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CEM parameters\n",
    "# Using the same parameters as from - https://github.com/SeldonIO/alibi/blob/master/doc/source/examples/cem_iris.ipynb\n",
    "\n",
    "mode = 'PN'  # 'PN' (pertinent negative) or 'PP' (pertinent positive)\n",
    "shape = X.shape  # data instance shape\n",
    "kappa = .2   # minimum difference needed between the prediction probability for the perturbed instance on the\n",
    "             # class predicted by the original instance and the max probability on the other classes \n",
    "             # in order for the first loss term to be minimized\n",
    "beta = .1   # weight of the L1 loss term\n",
    "c_init = 10.  # initial weight c of the loss term encouraging to predict a different class (PN) or \n",
    "              # the same class (PP) for the perturbed instance compared to the original instance to be explained\n",
    "c_steps = 10  # nb of updates for c\n",
    "max_iterations = 1000  # nb of iterations per value of c\n",
    "feature_range = (df_train.values.min(axis=0).reshape(shape)-.1,  # feature range for the perturbed instance\n",
    "                 df_train.values.min(axis=0).reshape(shape)+.1)  # can be either a float or array of shape (1xfeatures)\n",
    "clip = (-1000.,1000.)  # gradient clipping\n",
    "lr_init = 1e-2  # initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No PN found!\n"
     ]
    }
   ],
   "source": [
    "# initialize CEM explainer and explain instance\n",
    "cem = CEM(predict_fn, mode, shape, \n",
    "          kappa=kappa, beta=beta, feature_range=feature_range, \n",
    "          max_iterations=max_iterations, c_init=c_init, c_steps=c_steps, \n",
    "          learning_rate_init=lr_init, clip=clip)\n",
    "\n",
    "cem.fit(df_train.values, no_info_type='median') # we need to define what feature values contain the least\n",
    "                                                # info wrt predictions\n",
    "                                                # here we will naively assume that the feature-wise median\n",
    "                                                # contains no info; domain knowledge helps!\n",
    "explanation = cem.explain(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance:    Temperature  Humidity  Light    CO2  HumidityRatio\n",
      "0         23.7    26.272  585.2  749.2       0.004764\n",
      "Predicted class: not_occupied\n"
     ]
    }
   ],
   "source": [
    "print(f'Original instance: {explanation.X}')\n",
    "print(f'Predicted class: {class_names[explanation.X_pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertinent negative: None\n"
     ]
    }
   ],
   "source": [
    "print(f'Pertinent negative: {explanation.PN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, no pertinent negative is found. This indicates that all the features are important and considered by the model for the prediction. Usually for higher dimensional data, you might find PN to be very helpful. Now, let's find out PP for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CEM with pertinent positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'PP'\n",
    "\n",
    "# initialize CEM explainer and explain instance\n",
    "cem = CEM(predict_fn, mode, shape, kappa=kappa, \n",
    "          beta=beta, feature_range=feature_range, \n",
    "          max_iterations=max_iterations, c_init=c_init, c_steps=c_steps, \n",
    "          learning_rate_init=lr_init, clip=clip)\n",
    "cem.fit(df_train.values, no_info_type='median')\n",
    "explanation = cem.explain(X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertinent positive: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.629395e-07</td>\n",
       "      <td>6.408691e-07</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>6.468344e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature      Humidity     Light       CO2  HumidityRatio\n",
       "0 -7.629395e-07  6.408691e-07 -0.000012 -0.000012   6.468344e-11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: not_occupied\n"
     ]
    }
   ],
   "source": [
    "print(f'Pertinent positive: ')\n",
    "display.display(explanation.PP)\n",
    "print(f'Predicted class: {class_names[explanation.PP_pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further analyze the difference between PP and PN, but since we do not have any PN, we will not be able to compare with the generated PP values. Next, let us use Alibi for getting the counterfactuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CFE parameters for Alibi - from: https://github.com/SeldonIO/alibi/blob/master/doc/source/examples/cfproto_cat_adult_ohe.ipynb\n",
    "shape = X.shape\n",
    "beta = .01\n",
    "c_init = 1.\n",
    "c_steps = 5\n",
    "max_iterations = 500\n",
    "rng = (-1., 1.)  # scale features between -1 and 1\n",
    "\n",
    "feature_range = ((np.ones(shape) * rng[0]).astype(np.float32), \n",
    "                 (np.ones(shape) * rng[1]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfe = CounterfactualProto(predict_fn,\n",
    "                          shape,\n",
    "                          use_kdtree=True, \n",
    "                          theta=10., \n",
    "                          max_iterations=1000,\n",
    "                          c_init=1., \n",
    "                          c_steps=10\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No encoder specified. Using k-d trees to represent class prototypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSupported values for d_type is:\\n- 'abdm' infers context from the other variables \\n- 'mvdm' uses the model predictions.\\n- 'abdm-mvdm' is a weighted combination of the two metrics.\\n\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfe.fit(df_train.values, d_type='abdm', disc_perc=[25, 50, 75]);\n",
    "'''\n",
    "Supported values for d_type is:\n",
    "- 'abdm' infers context from the other variables \n",
    "- 'mvdm' uses the model predictions.\n",
    "- 'abdm-mvdm' is a weighted combination of the two metrics.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate counterfactuals for the test instance\n",
    "explanation = cfe.explain(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction: 0\n",
      "Counterfactual prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Original prediction: {explanation.orig_class}')\n",
    "print('Counterfactual prediction: {}'.format(explanation.cf['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>581</td>\n",
       "      <td>751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light  CO2  HumidityRatio\n",
       "0           23        25    581  751              0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's see the counterfactual example\n",
    "counterfactual = explanation.cf['X'].astype(int)\n",
    "change = counterfactual - X\n",
    "df_cfe = pd.DataFrame(counterfactual, columns = numeric)\n",
    "df_cfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature Temperature has to change by -0.7\n",
      "The feature Humidity has to change by -1.272\n",
      "The feature Light has to change by -4.2\n",
      "The feature CO2 has to change by 1.8\n",
      "The feature HumidityRatio has to change by -0.005\n"
     ]
    }
   ],
   "source": [
    "# Let's see the difference between counterfactual and original instance\n",
    "for i, feature_names in enumerate(numeric):\n",
    "    if change[feature_names][0] != 0:\n",
    "        print(f\"The feature {feature_names} has to change by {round(change[feature_names][0],3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can get the counterfactual examples. Although, I think further hyper-parameter tuning is required for generating the counterfactuals, as the degree of change for the feature values seems to b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulated Local Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset link - Occupancy Detection dataset | [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+#)\n",
    "2. ALIBI Github project - https://github.com/SeldonIO/alibi\n",
    "6. ALIBI Documentation - https://docs.seldon.io/projects/alibi/en/latest/\n",
    "7. Other notebook examples: https://github.com/SeldonIO/alibi/tree/master/doc/source/examples\n",
    "8. Some of the utility functions and code are taken from the GitHub Repository of the author - Aditya Bhattacharya https://github.com/adib0073\n",
    "9. Want to connect with the author of this chapter? You can reach out by any means mentioned here: https://aditya-bhattacharya.net/contact-me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
